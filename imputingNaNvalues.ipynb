{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# another way of ignoring warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x_01</th>\n",
       "      <th>x_02</th>\n",
       "      <th>x_03</th>\n",
       "      <th>x_04</th>\n",
       "      <th>x_05</th>\n",
       "      <th>x_06</th>\n",
       "      <th>x_07</th>\n",
       "      <th>x_08</th>\n",
       "      <th>x_09</th>\n",
       "      <th>...</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>C_01</th>\n",
       "      <th>C_02</th>\n",
       "      <th>C_03</th>\n",
       "      <th>C_04</th>\n",
       "      <th>C_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375.823073</td>\n",
       "      <td>6.359019</td>\n",
       "      <td>-13.367120</td>\n",
       "      <td>-2.483750</td>\n",
       "      <td>-6.641891</td>\n",
       "      <td>11.733539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.085361</td>\n",
       "      <td>22.194764</td>\n",
       "      <td>16.827888</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.200888</td>\n",
       "      <td>3.980048</td>\n",
       "      <td>-4.433274</td>\n",
       "      <td>-1.473723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266.811730</td>\n",
       "      <td>3.873664</td>\n",
       "      <td>-8.470389</td>\n",
       "      <td>-3.055012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.420983</td>\n",
       "      <td>1.822330</td>\n",
       "      <td>-13.694100</td>\n",
       "      <td>22.738654</td>\n",
       "      <td>20.307503</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.740207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.629314</td>\n",
       "      <td>4.816987</td>\n",
       "      <td>-12.240248</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>267.271759</td>\n",
       "      <td>5.275824</td>\n",
       "      <td>-12.070531</td>\n",
       "      <td>-1.366168</td>\n",
       "      <td>-4.819100</td>\n",
       "      <td>10.721527</td>\n",
       "      <td>-5.125992</td>\n",
       "      <td>-17.476865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.963889</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.501970</td>\n",
       "      <td>10.054005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.107921</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219.951294</td>\n",
       "      <td>4.430110</td>\n",
       "      <td>-4.467975</td>\n",
       "      <td>-0.730736</td>\n",
       "      <td>-10.047104</td>\n",
       "      <td>11.498539</td>\n",
       "      <td>-2.870260</td>\n",
       "      <td>-14.033012</td>\n",
       "      <td>18.225190</td>\n",
       "      <td>10.409488</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.086963</td>\n",
       "      <td>2.019726</td>\n",
       "      <td>-8.531959</td>\n",
       "      <td>3.520833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.697954</td>\n",
       "      <td>3.116458</td>\n",
       "      <td>-8.518713</td>\n",
       "      <td>-6.796050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.646285</td>\n",
       "      <td>-3.118309</td>\n",
       "      <td>-13.102567</td>\n",
       "      <td>22.801217</td>\n",
       "      <td>16.680208</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.117422</td>\n",
       "      <td>6.627601</td>\n",
       "      <td>-2.805531</td>\n",
       "      <td>5.914351</td>\n",
       "      <td>-11.240573</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>265.753204</td>\n",
       "      <td>2.478883</td>\n",
       "      <td>-10.347278</td>\n",
       "      <td>-3.574333</td>\n",
       "      <td>-4.320143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.326662</td>\n",
       "      <td>-13.197508</td>\n",
       "      <td>23.424267</td>\n",
       "      <td>12.551075</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.571283</td>\n",
       "      <td>7.487204</td>\n",
       "      <td>-5.098366</td>\n",
       "      <td>3.175914</td>\n",
       "      <td>-9.610356</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>133.594186</td>\n",
       "      <td>0.497803</td>\n",
       "      <td>-9.389992</td>\n",
       "      <td>-7.230404</td>\n",
       "      <td>-8.852222</td>\n",
       "      <td>12.308068</td>\n",
       "      <td>-5.288380</td>\n",
       "      <td>-9.998207</td>\n",
       "      <td>23.229430</td>\n",
       "      <td>13.491712</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.720359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.235942</td>\n",
       "      <td>4.124001</td>\n",
       "      <td>-16.268568</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>252.251096</td>\n",
       "      <td>7.627311</td>\n",
       "      <td>-7.146660</td>\n",
       "      <td>0.244472</td>\n",
       "      <td>0.182987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.395215</td>\n",
       "      <td>-14.423119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.710254</td>\n",
       "      <td>7.884195</td>\n",
       "      <td>-2.402023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.631043</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>163.402815</td>\n",
       "      <td>4.981034</td>\n",
       "      <td>-8.719028</td>\n",
       "      <td>-5.484942</td>\n",
       "      <td>-5.919929</td>\n",
       "      <td>9.916674</td>\n",
       "      <td>-4.726807</td>\n",
       "      <td>-10.606375</td>\n",
       "      <td>24.903043</td>\n",
       "      <td>12.151393</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.139651</td>\n",
       "      <td>7.096430</td>\n",
       "      <td>-2.865486</td>\n",
       "      <td>7.464922</td>\n",
       "      <td>-8.441735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>282.511836</td>\n",
       "      <td>0.519655</td>\n",
       "      <td>-14.477831</td>\n",
       "      <td>-2.121282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.080162</td>\n",
       "      <td>-6.393721</td>\n",
       "      <td>-11.599432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.984299</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.195198</td>\n",
       "      <td>2.409425</td>\n",
       "      <td>-3.523658</td>\n",
       "      <td>2.821658</td>\n",
       "      <td>-14.591262</td>\n",
       "      <td>75.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y      x_01       x_02      x_03       x_04       x_05      x_06  \\\n",
       "0  375.823073  6.359019 -13.367120 -2.483750  -6.641891  11.733539       NaN   \n",
       "1  266.811730  3.873664  -8.470389 -3.055012        NaN  11.420983  1.822330   \n",
       "2  267.271759  5.275824 -12.070531 -1.366168  -4.819100  10.721527 -5.125992   \n",
       "3  219.951294  4.430110  -4.467975 -0.730736 -10.047104  11.498539 -2.870260   \n",
       "4  289.697954  3.116458  -8.518713 -6.796050        NaN   7.646285 -3.118309   \n",
       "5  265.753204  2.478883 -10.347278 -3.574333  -4.320143        NaN -3.326662   \n",
       "6  133.594186  0.497803  -9.389992 -7.230404  -8.852222  12.308068 -5.288380   \n",
       "7  252.251096  7.627311  -7.146660  0.244472   0.182987        NaN -0.395215   \n",
       "8  163.402815  4.981034  -8.719028 -5.484942  -5.919929   9.916674 -4.726807   \n",
       "9  282.511836  0.519655 -14.477831 -2.121282        NaN  12.080162 -6.393721   \n",
       "\n",
       "        x_07       x_08       x_09  ...       x_91       x_92      x_93  \\\n",
       "0 -17.085361  22.194764  16.827888  ... -10.200888   3.980048 -4.433274   \n",
       "1 -13.694100  22.738654  20.307503  ...  -9.740207        NaN -2.629314   \n",
       "2 -17.476865        NaN  15.963889  ... -14.501970  10.054005       NaN   \n",
       "3 -14.033012  18.225190  10.409488  ... -11.086963   2.019726 -8.531959   \n",
       "4 -13.102567  22.801217  16.680208  ...  -9.117422   6.627601 -2.805531   \n",
       "5 -13.197508  23.424267  12.551075  ... -11.571283   7.487204 -5.098366   \n",
       "6  -9.998207  23.229430  13.491712  ... -15.720359        NaN -6.235942   \n",
       "7 -14.423119        NaN        NaN  ... -10.710254   7.884195 -2.402023   \n",
       "8 -10.606375  24.903043  12.151393  ... -11.139651   7.096430 -2.865486   \n",
       "9 -11.599432        NaN  11.984299  ... -14.195198   2.409425 -3.523658   \n",
       "\n",
       "       x_94       x_95  C_01  C_02  C_03  C_04  C_05  \n",
       "0 -1.473723        NaN  74.0  72.0  72.0  73.0  73.0  \n",
       "1  4.816987 -12.240248  74.0  72.0  72.0  73.0  73.0  \n",
       "2       NaN -11.107921  73.0  72.0  75.0  74.0  74.0  \n",
       "3  3.520833        NaN  71.0  72.0  73.0  71.0  72.0  \n",
       "4  5.914351 -11.240573  72.0  72.0  72.0  74.0  75.0  \n",
       "5  3.175914  -9.610356  71.0  72.0  74.0  71.0  75.0  \n",
       "6  4.124001 -16.268568  74.0  72.0  75.0  71.0  75.0  \n",
       "7       NaN  -4.631043  74.0  72.0  73.0  75.0  73.0  \n",
       "8  7.464922  -8.441735   NaN   NaN   NaN   NaN   NaN  \n",
       "9  2.821658 -14.591262  75.0  72.0  72.0  74.0  71.0  \n",
       "\n",
       "[10 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Importing data\n",
    "df = pd.read_csv(\"case1Data.csv\")\n",
    "y = df.iloc[:, 0]\n",
    "X = df.iloc[:, 1:]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaN values\n",
    "#### Instead of filling NaN values with mean of the predictor, use KNN Imputer (Scikit-Learn).\n",
    "This imputer utilizes the k-Nearest Neighbors method to replace the missing values in the datasets with the mean value from the parameter ‘n_neighbors’ nearest neighbors found in the training set. By default, it uses a Euclidean distance metric to impute the missing values.\n",
    "\n",
    "Another critical point here is that the KNN Imptuer is a distance-based imputation method and it requires us to normalize our data. Otherwise, the different scales of our data will lead the KNN Imputer to generate biased replacements for the missing values. For simplicity, we will use Scikit-Learn’s MinMaxScaler which will scale our variables to have values between 0 and 1.\n",
    "\n",
    "We are setting the parameter ‘n_neighbors’ as 5. So, the missing values will be replaced by the mean value of 5 nearest neighbors measured by Euclidean distance.\n",
    "\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "df_ = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_ = pd.DataFrame(imputer.fit_transform(df),columns = df.columns)\n",
    "df.head(10)\n",
    "```\n",
    "\n",
    "#### pypeline:\n",
    "1. spliting the data\n",
    "```python\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "```\n",
    "2. for continuous variables (X_cont) StandardScaler() followed by KNNImputer(n_neighbors=5) \n",
    "```python\n",
    "# starndartize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# apply KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5) \n",
    "X_train_imputed = imputer.fit_transform(X_train_scaled)\n",
    "X_test_imputed = imputer.transform(X_test_scaled)\n",
    "```\n",
    "3. for categorical variables (X_cat) SimpleImputer(strategy=\"most_frequent\") followed by 1-hot-encoding\n",
    "```python\n",
    "# impute categorical values using SimpleImputer\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train_imputed = cat_imputer.fit_transform(X_train)\n",
    "X_test_imputed = cat_imputer.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# train set\n",
    "Xtrain_cont = Xtrain.iloc[:, :95]\n",
    "Xtrain_cat = Xtrain.iloc[:, 95:]\n",
    "\n",
    "# test set\n",
    "Xtest_cont = Xtest.iloc[:, :95]\n",
    "Xtest_cat = Xtest.iloc[:, 95:]\n",
    "\n",
    "# --- Scaling Continuous Variables ---\n",
    "standard_scaler = StandardScaler()\n",
    "Xtrain_cont_scaled = standard_scaler.fit_transform(Xtrain_cont)\n",
    "Xtest_cont_scaled = standard_scaler.transform(Xtest_cont)\n",
    "\n",
    "# --- KNN Imputation for Continuous Variables ---\n",
    "knn_imput = KNNImputer(n_neighbors=5)\n",
    "X_train_cont_imputed = knn_imput.fit_transform(Xtrain_cont_scaled)\n",
    "X_test_cont_imputed = knn_imput.transform(Xtest_cont_scaled)\n",
    "\n",
    "# Convert to DataFrame \n",
    "X_train_cont_imputed = pd.DataFrame(X_train_cont_imputed, columns=Xtrain_cont.columns, index=Xtrain_cont.index)\n",
    "X_test_cont_imputed = pd.DataFrame(X_test_cont_imputed, columns=Xtest_cont.columns, index=Xtest_cont.index)\n",
    "\n",
    "# --- Imputation for Categorical Variables ---\n",
    "simple_imput = SimpleImputer(strategy=\"most_frequent\")\n",
    "Xtrain_cat_imputed = simple_imput.fit_transform(Xtrain_cat)\n",
    "Xtest_cat_imputed = simple_imput.transform(Xtest_cat)\n",
    "\n",
    "# Convert to DataFrame \n",
    "Xtrain_cat_imputed = pd.DataFrame(Xtrain_cat_imputed, columns=Xtrain_cat.columns, index=Xtrain_cat.index)\n",
    "Xtest_cat_imputed = pd.DataFrame(Xtest_cat_imputed, columns=Xtest_cat.columns, index=Xtest_cat.index)\n",
    "\n",
    "# --- 1 HOT encoding ---\n",
    "Xtrain_cat_imputed1HOT = pd.get_dummies(Xtrain_cat_imputed, columns=Xtrain_cat_imputed.columns, drop_first=False).astype(int)\n",
    "Xtest_cat_imputed1HOT = pd.get_dummies(Xtest_cat_imputed, columns=Xtrain_cat_imputed.columns, drop_first=False).astype(int)\n",
    "# Ensure that both train and test have the same columns\n",
    "Xtest_cat_imputed1HOT = Xtest_cat_imputed1HOT.reindex(columns=Xtrain_cat_imputed1HOT.columns, fill_value=0)\n",
    "\n",
    "# --- Align the target variable with the feature DataFrames ---\n",
    "# --- for Regression models ---\n",
    "# --- Concatenate Continuous and Categorical Data ---\n",
    "Xtrain_final = pd.concat([X_train_cont_imputed, Xtrain_cat_imputed1HOT], axis=1)\n",
    "Xtest_final = pd.concat([X_test_cont_imputed, Xtest_cat_imputed1HOT], axis=1)\n",
    "\n",
    "df_train_regression = pd.concat([ytrain, Xtrain_final], axis=1)\n",
    "df_test_regression = pd.concat([ytest, Xtest_final], axis=1)\n",
    "\n",
    "# --- for Trees ---\n",
    "# --- Concatenate Continuous and Categorical Data ---\n",
    "Xtrain_final = pd.concat([X_train_cont_imputed, Xtrain_cat_imputed], axis=1)\n",
    "Xtest_final = pd.concat([X_test_cont_imputed, Xtest_cat_imputed], axis=1)\n",
    "\n",
    "df_train_tree = pd.concat([ytrain, Xtrain_final], axis=1)\n",
    "df_test_tree = pd.concat([ytest, Xtest_final], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to seperate dataframes: Xytrain.csv and Xytest.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_regression.to_csv(\"Xytrain_regression.csv\")\n",
    "df_test_regression.to_csv(\"Xytest_regression.csv\")\n",
    "\n",
    "df_train_tree.to_csv(\"Xytrain_tree.csv\")\n",
    "df_test_tree.to_csv(\"Xytest_tree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
